import React, { useState, useEffect } from 'react';
import { useParams, useNavigate } from 'react-router-dom';
import { motion } from 'framer-motion';
import { ArrowLeft, Play, Pause, Clock, Volume2 } from 'lucide-react';
import TranscriptionDisplay from '../components/TranscriptionDisplay';

const TranscriptPage: React.FC = () => {
  const { id } = useParams();
  const navigate = useNavigate();
  const [isPlaying, setIsPlaying] = useState(false);
  const [currentTime, setCurrentTime] = useState(0);
  const [duration, setDuration] = useState(0);
  
  // Mock data - in a real app this would come from an API
  const transcript = {
    id: id,
    text: "This is a sample transcription. In a real application, this text would be generated by the Python ML model processing the uploaded audio file. The transcription would contain the full text content from the audio, properly formatted with timestamps and speaker identification where applicable.",
    audioUrl: "https://example.com/audio.mp3",
    createdAt: new Date().toISOString(),
    duration: 235 // seconds
  };
  
  useEffect(() => {
    setDuration(transcript.duration);
  }, [transcript]);
  
  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs < 10 ? '0' : ''}${secs}`;
  };
  
  const handlePlayPause = () => {
    setIsPlaying(!isPlaying);
    // In a real app, this would control actual audio playback
  };
  
  const handleTimeChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    const newTime = parseInt(e.target.value);
    setCurrentTime(newTime);
    // In a real app, this would seek to the specific time in the audio
  };
  
  return (
    <div className="container mx-auto px-4 py-8">
      <motion.div 
        initial={{ opacity: 0 }}
        animate={{ opacity: 1 }}
        className="max-w-4xl mx-auto"
      >
        <button 
          onClick={() => navigate(-1)}
          className="flex items-center text-blue-500 mb-6 hover:text-blue-700 transition-colors"
        >
          <ArrowLeft className="h-4 w-4 mr-1" />
          Back to all transcripts
        </button>
        
        <div className="bg-white rounded-xl shadow-md overflow-hidden mb-6">
          <div className="p-6">
            <h1 className="text-2xl font-bold text-gray-900 mb-4">
              Transcript #{id}
            </h1>
            
            <div className="flex items-center text-gray-500 mb-6">
              <Clock className="h-4 w-4 mr-1" />
              <span className="text-sm">{new Date(transcript.createdAt).toLocaleString()}</span>
            </div>
            
            <div className="mb-6 bg-gray-100 p-4 rounded-lg">
              <div className="flex items-center gap-4 mb-3">
                <button 
                  onClick={handlePlayPause}
                  className="p-2 bg-blue-500 text-white rounded-full hover:bg-blue-600 transition-colors"
                >
                  {isPlaying ? <Pause className="h-4 w-4" /> : <Play className="h-4 w-4" />}
                </button>
                
                <div className="flex-1">
                  <input
                    type="range"
                    min="0"
                    max={duration}
                    value={currentTime}
                    onChange={handleTimeChange}
                    className="w-full accent-blue-500"
                  />
                </div>
                
                <div className="text-sm">
                  {formatTime(currentTime)} / {formatTime(duration)}
                </div>
                
                <Volume2 className="h-5 w-5 text-gray-500" />
              </div>
              
              <div className="text-sm text-gray-500">
                Audio file: transcript-{id}.mp3
              </div>
            </div>
          </div>
        </div>
        
        <TranscriptionDisplay text={transcript.text} />
      </motion.div>
    </div>
  );
};

export default TranscriptPage;